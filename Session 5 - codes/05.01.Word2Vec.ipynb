{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown, movie_reviews, treebank\n",
    "br = Word2Vec(brown.sents())\n",
    "mr = Word2Vec(movie_reviews.sents())\n",
    "tb = Word2Vec(treebank.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('care', 0.9047278165817261),\n",
       " ('job', 0.9020060300827026),\n",
       " ('trouble', 0.8821300268173218),\n",
       " ('chance', 0.8704777359962463),\n",
       " ('work', 0.8690633177757263)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br.wv.most_similar('money', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('him', 0.7789386510848999),\n",
       " ('attention', 0.7512477040290833),\n",
       " ('trouble', 0.7276182174682617),\n",
       " ('eyes', 0.7269654870033264),\n",
       " ('ready', 0.7255377769470215)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr.wv.most_similar('money', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('when', 0.999602735042572),\n",
       " ('traders', 0.9995506405830383),\n",
       " ('only', 0.9995391964912415),\n",
       " ('into', 0.9995371699333191),\n",
       " ('managers', 0.9995243549346924)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.wv.most_similar('money', topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with your own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What an astonishing thing a book is. It's a flat object made from a tree with flexible parts on which are imprinted lots of funny dark squiggles. But one glance at it and you're inside the mind of another person, maybe somebody dead for thousands of years. Across the millennia, an author is speaking clearly and silently inside your head, directly to you. Writing is perhaps the greatest of human inventions, binding together people who never knew each other, citizens of distant epochs. Books break the shackles of time. A book is proof that humans are capable of working magic.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open('datasets/carl_sagan_quote.txt').read()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    result = []\n",
    "    sent = sent_tokenize(text)\n",
    "    for sentence in sent:\n",
    "        words = word_tokenize(sentence)\n",
    "        tokens = [w for w in words if w.lower() not in string.punctuation]\n",
    "        stopw = stopwords.words('english')\n",
    "        tokens = [token for token in tokens if token not in stopw]\n",
    "    # remove words less than three letters\n",
    "        tokens = [word for word in tokens if len(word)>=3]\n",
    "    # lemmatize\n",
    "        lemma = WordNetLemmatizer()\n",
    "        tokens = [lemma.lemmatize(word) for word in tokens]\n",
    "        result += [tokens] \n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['What', 'astonishing', 'thing', 'book'],\n",
       " ['flat',\n",
       "  'object',\n",
       "  'made',\n",
       "  'tree',\n",
       "  'flexible',\n",
       "  'part',\n",
       "  'imprinted',\n",
       "  'lot',\n",
       "  'funny',\n",
       "  'dark',\n",
       "  'squiggle'],\n",
       " ['But',\n",
       "  'one',\n",
       "  'glance',\n",
       "  \"'re\",\n",
       "  'inside',\n",
       "  'mind',\n",
       "  'another',\n",
       "  'person',\n",
       "  'maybe',\n",
       "  'somebody',\n",
       "  'dead',\n",
       "  'thousand',\n",
       "  'year'],\n",
       " ['Across',\n",
       "  'millennium',\n",
       "  'author',\n",
       "  'speaking',\n",
       "  'clearly',\n",
       "  'silently',\n",
       "  'inside',\n",
       "  'head',\n",
       "  'directly'],\n",
       " ['Writing',\n",
       "  'perhaps',\n",
       "  'greatest',\n",
       "  'human',\n",
       "  'invention',\n",
       "  'binding',\n",
       "  'together',\n",
       "  'people',\n",
       "  'never',\n",
       "  'knew',\n",
       "  'citizen',\n",
       "  'distant',\n",
       "  'epoch'],\n",
       " ['Books', 'break', 'shackle', 'time'],\n",
       " ['book', 'proof', 'human', 'capable', 'working', 'magic']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_p = preprocessing(text)\n",
    "text_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x269ef9d0b20>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size – Denotes the number of dimensions present in the vectorial forms.\n",
    "# If you have read the document and have an idea of how many ‘topics’ it has, you can use that number\n",
    "# sg = 0 for CBOW model and 1 for skip-gram model\n",
    "# min_count: Ignore all words with total frequency lower than this\n",
    "# window: the maximum distance between the current and predicted word within\n",
    "# a sentence.\n",
    "model = Word2Vec(text_p, min_count=1, sg=1, window =3)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('year', 0.21988043189048767)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['millennium','human'], negative=['magic'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('year', 0.7606932520866394)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar_cosmul(positive=['millennium', 'human'], negative=['magic'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('person', 0.26482051610946655)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['millennium','human','magic'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'magic'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"millennium human magic book\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06843189"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('book', 'invention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The word vectors are stored in a KeyedVectors instance in model.wv. \n",
    "#This separates the read-only word vector lookup operations in KeyedVectors from the training code in Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.3563481e-04,  2.3609448e-04,  5.1024966e-03,  9.0092830e-03,\n",
       "       -9.3017444e-03, -7.1180812e-03,  6.4584552e-03,  8.9766849e-03,\n",
       "       -5.0170152e-03, -3.7658883e-03,  7.3811240e-03, -1.5342073e-03,\n",
       "       -4.5357402e-03,  6.5539419e-03, -4.8570656e-03, -1.8155428e-03,\n",
       "        2.8765933e-03,  9.9167612e-04, -8.2854982e-03, -9.4494354e-03,\n",
       "        7.3100310e-03,  5.0693210e-03,  6.7569013e-03,  7.6063070e-04,\n",
       "        6.3500670e-03, -3.4060956e-03, -9.4749324e-04,  5.7659470e-03,\n",
       "       -7.5205108e-03, -3.9364761e-03, -7.5128879e-03, -9.3162252e-04,\n",
       "        9.5380517e-03, -7.3207384e-03, -2.3316094e-03, -1.9360896e-03,\n",
       "        8.0759106e-03, -5.9306626e-03,  4.5434106e-05, -4.7544036e-03,\n",
       "       -9.6032452e-03,  5.0068637e-03, -8.7601868e-03, -4.3897266e-03,\n",
       "       -3.3673325e-05, -2.9875373e-04, -7.6621128e-03,  9.6147563e-03,\n",
       "        4.9820123e-03,  9.2332605e-03, -8.1567885e-03,  4.4964016e-03,\n",
       "       -4.1376371e-03,  8.2622562e-04,  8.4987478e-03, -4.4611846e-03,\n",
       "        4.5187613e-03, -6.7883870e-03, -3.5460906e-03,  9.3988469e-03,\n",
       "       -1.5791131e-03,  3.2226139e-04, -4.1407668e-03, -7.6805167e-03,\n",
       "       -1.5090605e-03,  2.4732072e-03, -8.8939065e-04,  5.5344328e-03,\n",
       "       -2.7434577e-03,  2.2583900e-03,  5.4584281e-03,  8.3457315e-03,\n",
       "       -1.4532546e-03, -9.2072161e-03,  4.3714768e-03,  5.7118287e-04,\n",
       "        7.4442588e-03, -8.1335625e-04, -2.6369048e-03, -8.7529281e-03,\n",
       "       -8.5953018e-04,  2.8286537e-03,  5.4017459e-03,  7.0524253e-03,\n",
       "       -5.7035345e-03,  1.8609358e-03,  6.0891723e-03, -4.7969315e-03,\n",
       "       -3.1045133e-03,  6.7991475e-03,  1.6307906e-03,  1.8974724e-04,\n",
       "        3.4738367e-03,  2.1954007e-04,  9.6212830e-03,  5.0627938e-03,\n",
       "       -8.9181336e-03, -7.0422371e-03,  9.0183481e-04,  6.3906517e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word vector: vectorial representation.\n",
    "model.wv['book']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['book',\n",
       " 'inside',\n",
       " 'human',\n",
       " 'magic',\n",
       " 'squiggle',\n",
       " 'dead',\n",
       " 'somebody',\n",
       " 'maybe',\n",
       " 'person',\n",
       " 'another']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(model.wv.index_to_key)\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing and Loading models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('datasets/word2vec_model')\n",
    "new_model = Word2Vec.load('datasets/word2vec_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('binding', 0.20213058590888977),\n",
       " ('break', 0.19651201367378235),\n",
       " ('person', 0.19567753374576569)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.wv.most_similar(positive=['human','magic'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ = Word2Vec(text_p, min_count=1, sg=1, window =3, hs=1, negative=0)\n",
    "model_.score([\"The cosmos a space time odyssey\".split()]) #Probability of a text under the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference:\n",
    "\n",
    "https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "https://pypi.python.org/pypi/gensim\n",
    "\n",
    "https://radimrehurek.com/gensim/\n",
    "\n",
    "https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
