{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Pics/MLSb-T.png\" width=\"160\">\n",
    "<br><br>\n",
    "<center><u><H1>Word2Vec</H1></u></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation:\n",
    " \n",
    " pip install -U gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown, movie_reviews, treebank\n",
    "br = Word2Vec(brown.sents())\n",
    "mr = Word2Vec(movie_reviews.sents())\n",
    "tb = Word2Vec(treebank.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br.most_similar('money', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr.most_similar('money', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.most_similar('money', topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with your own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('../Data/carl_sagan_quote.txt').read()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    result = []\n",
    "    sent = sent_tokenize(text)\n",
    "    for sentence in sent:\n",
    "        words = word_tokenize(sentence)\n",
    "        tokens = [w for w in words if w.lower() not in string.punctuation]\n",
    "        stopw = stopwords.words('english')\n",
    "        tokens = [token for token in tokens if token not in stopw]\n",
    "    # remove words less than three letters\n",
    "        tokens = [word for word in tokens if len(word)>=3]\n",
    "    # lemmatize\n",
    "        lemma = WordNetLemmatizer()\n",
    "        tokens = [lemma.lemmatize(word) for word in tokens]\n",
    "        result += [tokens] \n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_p = preprocessing(text)\n",
    "text_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size – Denotes the number of dimensions present in the vectorial forms.\n",
    "# If you have read the document and have an idea of how many ‘topics’ it has, you can use that number\n",
    "# sg = 0 for CBOW model and 1 for skip-gram model\n",
    "# min_count: Ignore all words with total frequency lower than this\n",
    "# window: the maximum distance between the current and predicted word within\n",
    "# a sentence.\n",
    "model = Word2Vec(text_p, min_count=1, sg=1, window =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=['millennium','human'], negative=['magic'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar_cosmul(positive=['millennium', 'human'], negative=['magic'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=['millennium','human','magic'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.doesnt_match(\"millennium human magic book\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('book', 'invention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The word vectors are stored in a KeyedVectors instance in model.wv. \n",
    "#This separates the read-only word vector lookup operations in KeyedVectors from the training code in Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word vector: vectorial representation.\n",
    "model.wv['book']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(model.wv.vocab.keys())\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing and Loading models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('../Data/word2vec_model')\n",
    "new_model = Word2Vec.load('../Data/word2vec_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.wv.most_similar(positive=['human','magic'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = Word2Vec(text_p, min_count=1, sg=1, window =3, hs=1, negative=0)\n",
    "model_.score([\"The cosmos a space time odyssey\".split()]) #Probability of a text under the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference:\n",
    "\n",
    "https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "https://pypi.python.org/pypi/gensim\n",
    "\n",
    "https://radimrehurek.com/gensim/\n",
    "\n",
    "https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
